{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a46499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6df867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2d53ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/30 10:33:00 WARN Utils: Your hostname, Adedayos-MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.2.27 instead (on interface en0)\n",
      "23/04/30 10:33:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/30 10:33:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/30 10:33:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.config(\"spark.driver.memory\",\"12g\").config(\"spark.memory.offHeap.enabled\",\"true\") .config(\"spark.memory.offHeap.size\",\"10g\").appName('task3_regression_ml_with_spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec70799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.2.27:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>task3_regression_ml_with_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x16916e990>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a190d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+---------------------+\n",
      "|Symbol|Volume_New|vol_moving_avg|adj_close_rolling_med|\n",
      "+------+----------+--------------+---------------------+\n",
      "|    AB|  471200.0|          null|                  NaN|\n",
      "|    AB|  430000.0|      471200.0|           0.03649914|\n",
      "|    AB|  430000.0|      450600.0|           0.03694973|\n",
      "+------+----------+--------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = './ml_input_data.parquet/*.parquet'\n",
    "pyspark_df = spark.read.parquet(file_path, header=True, inferSchema=True)\n",
    "pyspark_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf06eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_df = pyspark_df.na.drop(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a138235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------+---------------------+\n",
      "|Symbol|Volume_New|   vol_moving_avg|adj_close_rolling_med|\n",
      "+------+----------+-----------------+---------------------+\n",
      "|    AB|  430000.0|         471200.0|           0.03649914|\n",
      "|    AB|  430000.0|         450600.0|           0.03694973|\n",
      "|    AB|  430000.0|443733.3333333333|          0.037400328|\n",
      "|    AB|  376400.0|         440300.0|          0.037400328|\n",
      "|    AB|  364400.0|         427520.0|          0.037400328|\n",
      "+------+----------+-----------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c6bdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, StringIndexerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2a0e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build indexer\n",
    "string_indexer = StringIndexer(inputCol='Symbol', outputCol='Indexed_Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2694bf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# learn the model\n",
    "string_indexer_model = string_indexer.fit(pyspark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9c8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "pyspark_df_stringindexer = string_indexer_model.transform(pyspark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "497f7313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------+---------------------+--------------+\n",
      "|Symbol|Volume_New|   vol_moving_avg|adj_close_rolling_med|Indexed_Symbol|\n",
      "+------+----------+-----------------+---------------------+--------------+\n",
      "|    AB|  430000.0|         471200.0|           0.03649914|         874.0|\n",
      "|    AB|  430000.0|         450600.0|           0.03694973|         874.0|\n",
      "|    AB|  430000.0|443733.3333333333|          0.037400328|         874.0|\n",
      "|    AB|  376400.0|         440300.0|          0.037400328|         874.0|\n",
      "|    AB|  364400.0|         427520.0|          0.037400328|         874.0|\n",
      "+------+----------+-----------------+---------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df_stringindexer.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48643877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=[\"Indexed_Symbol\",\"vol_moving_avg\", \"adj_close_rolling_med\"],\n",
    "                                 outputCol=\"Independent Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "926f170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pyspark_df=featureassembler.transform(pyspark_df_stringindexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67a9899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------+---------------------+--------------+--------------------+\n",
      "|Symbol|Volume_New|   vol_moving_avg|adj_close_rolling_med|Indexed_Symbol|Independent Features|\n",
      "+------+----------+-----------------+---------------------+--------------+--------------------+\n",
      "|    AB|  430000.0|         471200.0|           0.03649914|         874.0|[874.0,471200.0,0...|\n",
      "|    AB|  430000.0|         450600.0|           0.03694973|         874.0|[874.0,450600.0,0...|\n",
      "|    AB|  430000.0|443733.3333333333|          0.037400328|         874.0|[874.0,443733.333...|\n",
      "|    AB|  376400.0|         440300.0|          0.037400328|         874.0|[874.0,440300.0,0...|\n",
      "|    AB|  364400.0|         427520.0|          0.037400328|         874.0|[874.0,427520.0,0...|\n",
      "+------+----------+-----------------+---------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_pyspark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cd7a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_input_data=new_pyspark_df.select(\"Independent Features\",\"Volume_New\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575de4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|Independent Features|Volume_New|\n",
      "+--------------------+----------+\n",
      "|[874.0,471200.0,0...|  430000.0|\n",
      "|[874.0,450600.0,0...|  430000.0|\n",
      "|[874.0,443733.333...|  430000.0|\n",
      "|[874.0,440300.0,0...|  376400.0|\n",
      "|[874.0,427520.0,0...|  364400.0|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_input_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linear regression modelling\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cc28e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/30 10:47:47 WARN Instrumentation: [ff485157] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/04/30 10:48:04 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/30 10:48:18 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "##train test split\n",
    "train_data,test_data=ml_input_data.randomSplit([0.8,0.2])\n",
    "regressor=LinearRegression(featuresCol='Independent Features', labelCol='Volume_New')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "312ed3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-8.8942, 0.9632, 0.0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Coefficients\n",
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69eb08d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Prediction\n",
    "pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77c213c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+\n",
      "|Independent Features|Volume_New|        prediction|\n",
      "+--------------------+----------+------------------+\n",
      "|[9.0,1026630.0,0....|  938400.0|1047515.1484261984|\n",
      "|[9.0,1031623.3333...|  878500.0|1052324.8031515302|\n",
      "|[9.0,1048916.6666...|  668900.0| 1068982.005230984|\n",
      "|[9.0,1049250.0,0....| 1108200.0| 1069303.076974998|\n",
      "|[9.0,1050256.6666...|  998400.0|1070272.7136419206|\n",
      "+--------------------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa3868ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436367.8819334006, 38987836190980.22, 6244024.038308967)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError,pred_results.meanSquaredError, pred_results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab6a5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_actual_mean = pred_results.predictions.agg({'Volume_New':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51a88d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   avg(Volume_New)|\n",
      "+------------------+\n",
      "|1107345.1757088697|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_y_actual_mean.select('avg(Volume_New)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "925c1046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563.8733229060072"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_results.rootMeanSquaredError / 1107345.1757088697 ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random Forest Regression\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce9acd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressionModel, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fd91c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_Regressor = RandomForestRegressor(featuresCol='Independent Features', labelCol='Volume_New', maxBins=8043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8523d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[featureassembler, RR_Regressor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63cb7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_train_data,rr_test_data=pyspark_df_stringindexer.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "83c459e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/30 11:37:28 WARN MemoryStore: Not enough space to cache rdd_137_1 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:37:28 WARN BlockManager: Persisting block rdd_137_1 to disk instead.\n",
      "23/04/30 11:37:28 WARN MemoryStore: Not enough space to cache rdd_137_0 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:37:28 WARN BlockManager: Persisting block rdd_137_0 to disk instead.\n",
      "23/04/30 11:37:38 WARN MemoryStore: Not enough space to cache rdd_137_7 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:37:38 WARN MemoryStore: Not enough space to cache rdd_137_3 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:37:38 WARN BlockManager: Persisting block rdd_137_3 to disk instead.\n",
      "23/04/30 11:37:38 WARN BlockManager: Persisting block rdd_137_7 to disk instead.\n",
      "23/04/30 11:37:39 WARN MemoryStore: Not enough space to cache rdd_137_6 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:37:39 WARN BlockManager: Persisting block rdd_137_6 to disk instead.\n",
      "23/04/30 11:37:39 WARN MemoryStore: Not enough space to cache rdd_137_4 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:37:39 WARN BlockManager: Persisting block rdd_137_4 to disk instead.\n",
      "23/04/30 11:38:06 WARN MemoryStore: Not enough space to cache rdd_137_3 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:38:06 WARN MemoryStore: Not enough space to cache rdd_137_7 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:38:06 WARN MemoryStore: Not enough space to cache rdd_137_0 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:38:39 WARN MemoryStore: Not enough space to cache rdd_137_0 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:38:39 WARN MemoryStore: Not enough space to cache rdd_137_3 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:38:39 WARN MemoryStore: Not enough space to cache rdd_137_7 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:39:06 WARN DAGScheduler: Broadcasting large task binary with size 1094.9 KiB\n",
      "23/04/30 11:39:26 WARN MemoryStore: Not enough space to cache rdd_137_0 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:39:26 WARN MemoryStore: Not enough space to cache rdd_137_7 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:39:26 WARN MemoryStore: Not enough space to cache rdd_137_3 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:39:49 WARN DAGScheduler: Broadcasting large task binary with size 1548.9 KiB\n",
      "23/04/30 11:40:08 WARN MemoryStore: Not enough space to cache rdd_137_3 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:40:08 WARN MemoryStore: Not enough space to cache rdd_137_7 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:40:09 WARN MemoryStore: Not enough space to cache rdd_137_0 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:40:35 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/04/30 11:40:52 WARN MemoryStore: Not enough space to cache rdd_137_0 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:40:52 WARN MemoryStore: Not enough space to cache rdd_137_3 in memory! (computed 493.2 MiB so far)\n",
      "23/04/30 11:40:52 WARN MemoryStore: Not enough space to cache rdd_137_7 in memory! (computed 493.2 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "RR_Regressor=pipeline.fit(rr_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ef1ac2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "predictions = RR_Regressor.transform(rr_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7c0e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 44:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------+---------------------+--------------+--------------------+------------------+\n",
      "|Symbol|Volume_New|    vol_moving_avg|adj_close_rolling_med|Indexed_Symbol|Independent Features|        prediction|\n",
      "+------+----------+------------------+---------------------+--------------+--------------------+------------------+\n",
      "|    AB|    9600.0|           84320.0|            0.8204644|         874.0|[874.0,84320.0,0....| 297903.3446872417|\n",
      "|    AB|   11000.0|28486.666666666668|            1.3839588|         874.0|[874.0,28486.6666...| 297903.3446872417|\n",
      "|    AB|   16400.0|43706.666666666664|           0.06333716|         874.0|[874.0,43706.6666...|359376.43049111945|\n",
      "|    AB|   17200.0| 79093.33333333333|           0.62116843|         874.0|[874.0,79093.3333...| 297903.3446872417|\n",
      "|    AB|   17400.0|31353.333333333332|            1.3806239|         874.0|[874.0,31353.3333...| 297903.3446872417|\n",
      "+------+----------+------------------+---------------------+--------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2459d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionEvaluator_93eb9389999f"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "evaluator.setLabelCol(\"Volume_New\")\n",
    "evaluator.setMetricName(\"rmse\")\n",
    "#(PredictionCol='prediction', labelCol='Volume_New')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4c04333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionEvaluator_afbe64d17dbb"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator2 = RegressionEvaluator()\n",
    "evaluator2.setPredictionCol(\"prediction\")\n",
    "evaluator2.setLabelCol(\"Volume_New\")\n",
    "evaluator2.setMetricName(\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc711295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6469058.527134548"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f945b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584.1953050450926"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rmse / 1107345.1757088697 ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ddbae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "723967.8856936437"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = evaluator2.evaluate(predictions)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE: {LR: 436,367.8819334006 , RR: 723,967.8856936437}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c4e8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f19445b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_indexer_model.save(\"./string_indexer/model/mySI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1c3058c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_mystringindexer = StringIndexerModel.load(\"./string_indexer/model/mySI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1171d34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- vol_moving_avg: long (nullable = true)\n",
      " |-- adj_close_rolling_med: long (nullable = true)\n",
      "\n",
      "+------+--------------+---------------------+\n",
      "|Symbol|vol_moving_avg|adj_close_rolling_med|\n",
      "+------+--------------+---------------------+\n",
      "|AB    |10000         |600                  |\n",
      "+------+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('AB',10000,600)]\n",
    "dataColumns = [\"Symbol\",\"vol_moving_avg\", \"adj_close_rolling_med\"]\n",
    "dataDF = spark.createDataFrame(data=data, schema = dataColumns)\n",
    "dataDF.printSchema()\n",
    "dataDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e918ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------+--------------+\n",
      "|Symbol|vol_moving_avg|adj_close_rolling_med|Indexed_Symbol|\n",
      "+------+--------------+---------------------+--------------+\n",
      "|    AB|         10000|                  600|         874.0|\n",
      "+------+--------------+---------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = load_mystringindexer.transform(dataDF)\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "26cfd856",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureassembler.save('./vector_assembler/model/myVA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ad52b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedAssembler = VectorAssembler.load('./vector_assembler/model/myVA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7488f091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------+--------------+--------------------+\n",
      "|Symbol|vol_moving_avg|adj_close_rolling_med|Indexed_Symbol|Independent Features|\n",
      "+------+--------------+---------------------+--------------+--------------------+\n",
      "|    AB|         10000|                  600|         874.0|[874.0,10000.0,60...|\n",
      "+------+--------------+---------------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler_df = loadedAssembler.transform(test_df)\n",
    "assembler_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "975cc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = assembler_df.select('Independent Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0e161df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regressor.save(\"./linear_regression/model/myLR\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a8ecd80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "14475137",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedModel= LinearRegressionModel.load(\"./linear_regression/model/myLR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80eea8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel: uid=LinearRegression_4399efe7fa28, numFeatures=3"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "09a5dac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|Independent Features|       prediction|\n",
      "+--------------------+-----------------+\n",
      "|[874.0,10000.0,60...|60588.14570159758|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred=savedModel.transform(test_data)\n",
    "y_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0bd957f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = y_pred.select('prediction').toJSON().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "634ff117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "prediction_json = json.loads(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1101d795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60588.14570159758"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_json['prediction'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26d5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
